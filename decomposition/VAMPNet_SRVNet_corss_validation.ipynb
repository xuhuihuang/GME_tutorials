{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54e94286",
   "metadata": {},
   "source": [
    "# SRVNet cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a44acd1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:01<00:00, 18.97it/s]\n",
      "load data: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 19.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is starting...\n",
      "==>epoch=0, training process=33.33%, the training loss function=1.3315860033035278, eigenvalues:[0.49641174 0.2918243 ];\n",
      "==>epoch=0, training process=33.33%, the validation loss function=2.059948444366455;\n",
      "==>epoch=1, training process=66.67%, the training loss function=1.4312770366668701, eigenvalues:[0.5502906  0.35840952];\n",
      "==>epoch=1, training process=66.67%, the validation loss function=2.0941214561462402;\n",
      "==>epoch=2, training process=100.00%, the training loss function=1.5323909521102905, eigenvalues:[0.597474  0.4188267];\n",
      "==>epoch=2, training process=100.00%, the validation loss function=2.12217378616333;\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 18.76it/s]\n",
      "/home/yqiu78/anaconda/envs/pytorch/lib/python3.9/site-packages/numpy/lib/npyio.py:501: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n",
      "load data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:01<00:00, 18.33it/s]\n",
      "load data: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 19.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is starting...\n",
      "==>epoch=0, training process=33.33%, the training loss function=1.3564165830612183, eigenvalues:[0.5460421  0.24135987];\n",
      "==>epoch=0, training process=33.33%, the validation loss function=1.561816692352295;\n",
      "==>epoch=1, training process=66.67%, the training loss function=1.4790363311767578, eigenvalues:[0.636523  0.2717991];\n",
      "==>epoch=1, training process=66.67%, the validation loss function=1.6239337921142578;\n",
      "==>epoch=2, training process=100.00%, the training loss function=1.585392951965332, eigenvalues:[0.70429194 0.29894125];\n",
      "==>epoch=2, training process=100.00%, the validation loss function=1.6807923316955566;\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 19.16it/s]\n",
      "load data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:01<00:00, 19.21it/s]\n",
      "load data: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 19.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is starting...\n",
      "==>epoch=0, training process=33.33%, the training loss function=1.3413852453231812, eigenvalues:[0.57477534 0.10496929];\n",
      "==>epoch=0, training process=33.33%, the validation loss function=1.6470134258270264;\n",
      "==>epoch=1, training process=66.67%, the training loss function=1.4816646575927734, eigenvalues:[0.6846812  0.11347363];\n",
      "==>epoch=1, training process=66.67%, the validation loss function=1.6921864748001099;\n",
      "==>epoch=2, training process=100.00%, the training loss function=1.6051278114318848, eigenvalues:[0.7685863  0.12001208];\n",
      "==>epoch=2, training process=100.00%, the validation loss function=1.7248921394348145;\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 19.50it/s]\n",
      "load data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:01<00:00, 19.55it/s]\n",
      "load data: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 19.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is starting...\n",
      "==>epoch=0, training process=33.33%, the training loss function=1.3630365133285522, eigenvalues:[0.59686005 0.08242927];\n",
      "==>epoch=0, training process=33.33%, the validation loss function=1.5962040424346924;\n",
      "==>epoch=1, training process=66.67%, the training loss function=1.440946102142334, eigenvalues:[0.65696025 0.09669174];\n",
      "==>epoch=1, training process=66.67%, the validation loss function=1.6254653930664062;\n",
      "==>epoch=2, training process=100.00%, the training loss function=1.5035536289215088, eigenvalues:[0.7013246  0.10815507];\n",
      "==>epoch=2, training process=100.00%, the validation loss function=1.647284984588623;\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 19.43it/s]\n",
      "load data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:01<00:00, 19.67it/s]\n",
      "load data: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 19.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is starting...\n",
      "==>epoch=0, training process=33.33%, the training loss function=1.6305315494537354, eigenvalues:[0.73952067 0.26052237 0.12557407];\n",
      "==>epoch=0, training process=33.33%, the validation loss function=2.25898814201355;\n",
      "==>epoch=1, training process=66.67%, the training loss function=1.7089447975158691, eigenvalues:[0.769935   0.30732703 0.14729223];\n",
      "==>epoch=1, training process=66.67%, the validation loss function=2.2866737842559814;\n",
      "==>epoch=2, training process=100.00%, the training loss function=1.7942153215408325, eigenvalues:[0.79580367 0.36609617 0.16396789];\n",
      "==>epoch=2, training process=100.00%, the validation loss function=2.3086047172546387;\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 19.43it/s]\n",
      "load data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:01<00:00, 19.41it/s]\n",
      "load data: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 19.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is starting...\n",
      "==>epoch=0, training process=33.33%, the training loss function=1.4903067350387573, eigenvalues:[0.6462383  0.2644483  0.05243928];\n",
      "==>epoch=0, training process=33.33%, the validation loss function=2.071075916290283;\n",
      "==>epoch=1, training process=66.67%, the training loss function=1.584977388381958, eigenvalues:[0.6950179  0.31509635 0.05139849];\n",
      "==>epoch=1, training process=66.67%, the validation loss function=2.0917582511901855;\n",
      "==>epoch=2, training process=100.00%, the training loss function=1.668588638305664, eigenvalues:[0.73315424 0.35845453 0.05083131];\n",
      "==>epoch=2, training process=100.00%, the validation loss function=2.108994960784912;\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 19.49it/s]\n",
      "load data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:01<00:00, 19.63it/s]\n",
      "load data: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 19.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is starting...\n",
      "==>epoch=0, training process=33.33%, the training loss function=1.3708285093307495, eigenvalues:[0.5232181  0.31148428 0.00699098];\n",
      "==>epoch=0, training process=33.33%, the validation loss function=1.9269356727600098;\n",
      "==>epoch=1, training process=66.67%, the training loss function=1.5181307792663574, eigenvalues:[0.6356645  0.33767366 0.00615727];\n",
      "==>epoch=1, training process=66.67%, the validation loss function=1.9292519092559814;\n",
      "==>epoch=2, training process=100.00%, the training loss function=1.6488748788833618, eigenvalues:[0.7233968  0.35431325 0.005836  ];\n",
      "==>epoch=2, training process=100.00%, the validation loss function=1.928896188735962;\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 19.46it/s]\n",
      "load data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:01<00:00, 19.71it/s]\n",
      "load data: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 19.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is starting...\n",
      "==>epoch=0, training process=33.33%, the training loss function=1.0868654251098633, eigenvalues:[0.22616443 0.188238   0.01677885];\n",
      "==>epoch=0, training process=33.33%, the validation loss function=1.657677173614502;\n",
      "==>epoch=1, training process=66.67%, the training loss function=1.1920018196105957, eigenvalues:[0.37477717 0.22601333 0.02149165];\n",
      "==>epoch=1, training process=66.67%, the validation loss function=1.6744961738586426;\n",
      "==>epoch=2, training process=100.00%, the training loss function=1.3398652076721191, eigenvalues:[0.52876496 0.24421231 0.02516141];\n",
      "==>epoch=2, training process=100.00%, the validation loss function=1.6874561309814453;\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01<00:00, 19.53it/s]\n",
      "load data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:01<00:00, 19.46it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lag \u001b[38;5;129;01min\u001b[39;00m lagtime:\n\u001b[1;32m     28\u001b[0m     train_data \u001b[38;5;241m=\u001b[39m [trajs[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m train_idx]; test_data \u001b[38;5;241m=\u001b[39m [trajs[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m test_idx]\n\u001b[0;32m---> 29\u001b[0m     train_data \u001b[38;5;241m=\u001b[39m TimeLaggedDataset(trajs\u001b[38;5;241m=\u001b[39mtrain_data, lagtime\u001b[38;5;241m=\u001b[39mlag); test_data \u001b[38;5;241m=\u001b[39m TimeLaggedDataset(trajs\u001b[38;5;241m=\u001b[39mtest_data, lagtime\u001b[38;5;241m=\u001b[39mlag)\n\u001b[1;32m     30\u001b[0m     train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_data, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50000\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     31\u001b[0m     test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_data, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(test_data), shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/workspace/231005_VAMPNet_SRVNet_codes_rewrite/VAMPNet_SRVNet.py:59\u001b[0m, in \u001b[0;36mTimeLaggedDataset\u001b[0;34m(trajs, lagtime, normalize, mean, std)\u001b[0m\n\u001b[1;32m     57\u001b[0m     _pastdata \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m past_mean[\u001b[38;5;28;01mNone\u001b[39;00m, :]; _pastdata \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m past_std[\u001b[38;5;28;01mNone\u001b[39;00m, :]\n\u001b[1;32m     58\u001b[0m     _futuredata \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m future_mean[\u001b[38;5;28;01mNone\u001b[39;00m, :]; _futuredata \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m future_std[\u001b[38;5;28;01mNone\u001b[39;00m, :]\n\u001b[0;32m---> 59\u001b[0m _pastdata\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32); \u001b[43m_futuredata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m _pastdata \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(_pastdata); _futuredata \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(_futuredata)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _pastdata, _futuredata\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from VAMPNet_SRVNet import *\n",
    "from sklearn.model_selection import KFold\n",
    "import os\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "### Split the dataset into # of folders and generate training and validation dataset respectively\n",
    "### Do the cross validation based on trajectories instead of transition pairs\n",
    "\n",
    "### set number of trajectories in total\n",
    "num_trajs = 100\n",
    "\n",
    "### set the lagtime and number of cv to do cross validation\n",
    "### Note if GMRQ is implemented as criterion, need further clustering and MSM construction\n",
    "lagtime = [5, 10, 20, 40]\n",
    "num_cvs = [2, 3, 4, 5, 6]\n",
    "\n",
    "### set training hyper-parameters\n",
    "training_batch = 50000\n",
    "num_epochs = 5\n",
    "learning_rate = 1e-4\n",
    "\n",
    "### specify the output address\n",
    "output_dir = 'cross_validation_srvnet_num_cv_lagtime_5epochs_5e4batch_1e-4learning'\n",
    "\n",
    "\n",
    "### set the device (not necessary)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "## Set the random seed to ensure the reproducible training(not necessary)\n",
    "set_random_seed(42)\n",
    "\n",
    "os.makedirs(output_dir)\n",
    "trajs = np.load(\"./alanine_dipeptide_45pairwise_distances_100trajs_0.1ps.npy\", allow_pickle=True).item()\n",
    "trajs = [i for i in trajs.values()]\n",
    "trajs_idx = [i for i in range(num_trajs)]; k_folder = KFold(n_splits=5, shuffle=True, random_state=random_seed)\n",
    "num_folder = 0\n",
    "for train_idx, test_idx in k_folder.split(trajs_idx):\n",
    "    for num_cv in num_cvs:\n",
    "        for lag in lagtime:\n",
    "            train_data = [trajs[i] for i in train_idx]; test_data = [trajs[i] for i in test_idx]\n",
    "            train_data = TimeLaggedDataset(trajs=train_data, lagtime=lag); test_data = TimeLaggedDataset(trajs=test_data, lagtime=lag)\n",
    "            train_loader = DataLoader(train_data, batch_size=training_batch, shuffle=True)\n",
    "            test_loader = DataLoader(test_data, batch_size=len(test_data), shuffle=True)\n",
    "\n",
    "            lobe = torch.nn.Sequential(\n",
    "            torch.nn.BatchNorm1d(45),\n",
    "            torch.nn.Linear(45, 45), torch.nn.ELU(),\n",
    "            torch.nn.Linear(45, 20), torch.nn.ELU(),\n",
    "            torch.nn.Linear(20, num_cv))\n",
    "            lobe = lobe.to(device=device)\n",
    "\n",
    "            projector = deep_projector(network_type='SRVNet', lobe=lobe, epsilon=1e-6, learning_rate=learning_rate, device=device)\n",
    "            print(\"Training is starting...\")\n",
    "            projector.fit(train_loader=train_loader, num_epochs=num_epochs, validation_loader=test_loader)\n",
    "            torch.save(projector, output_dir+\"/alanine_dipeptide_45pairdistances_srvnet_{}randomseed_{}pslag_{}cvs_{}folder_model.th\".format(random_seed, lag/10, num_cv, num_folder))\n",
    "\n",
    "            training_score = np.array(projector.train_score)\n",
    "            validation_score = np.array(projector.validate_score)\n",
    "            np.savetxt(output_dir+\"/alanine_dipeptide_45pairdistances_srvnet_{}randomseed_{}nslag_{}cvs_{}folder_validation_score.txt\".format(random_seed, lag/10, num_cv, num_folder), validation_score)\n",
    "            np.savetxt(output_dir+\"/alanine_dipeptide_45pairdistances_srvnet_{}randomseed_{}nslag_{}cvs_{}folder_training_score.txt\".format(random_seed, lag/10, num_cv, num_folder), training_score)\n",
    "            \n",
    "            \n",
    "            project_trajs = projector.transform(trajs)\n",
    "            np.save(output_dir+\"/alanine_dipeptide_45pairdistances_srvnet_{}randomseed_{}nslag_{}cvs_{}folder_trajs.npy\".format(random_seed, lag/10, num_cv, num_folder), project_trajs)\n",
    "    num_folder += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9873f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
